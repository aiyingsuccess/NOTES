1.

torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.
For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.

If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.


2. Structure

torch.Tensor - A multi-dimensional array with support for autograd operations like backward(). Also holds the gradient w.r.t. the tensor.
nn.Module - Neural network module. Convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.
nn.Parameter - A kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a Module.
autograd.Function - Implements forward and backward definitions of an autograd operation. Every Tensor operation creates at least a single Function node
that connects to functions that created a Tensor and encodes its history.

3.funtion  .view(-1,3) -1 is the dimension size depends on 3 and the total numbers

4.function .data to get the raw number from tensor

5.Remember to first initialize the models and optimizers, then load the dictionary locally.

modelA = Net()
optimModelA = optim.SGD(modelA.parameters(), lr=0.001, momentum=0.9)

